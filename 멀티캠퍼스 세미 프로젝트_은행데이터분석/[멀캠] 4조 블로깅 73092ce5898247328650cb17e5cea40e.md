# [멀캠] 4조 블로깅

안녕하세요. 이번 시간에는 Kaggle Playground Prediction Competition(예측 대회)의 Bank Churn의 데이터를 활용하여 데이터 분석을 진행해보았습니다.

---

# Bank Churn 데이터에 대한 개요

- 본 데이터셋은 은행 고객 이탈 예측 데이터셋에서 생성되었습니다.
    - 대회에 포함된 데이터셋 : train.csv, test.csv, sample_submission.csv
- **본 포스팅에서 사용된 데이터셋 : train.csv**

## 각 데이터 컬럼에 대한 설명:

- **Customer ID(고객 ID):** 각 고객을 식별하는 고유 식별자
- **Surname(성):** 고객의 성
- **Credit Score(신용 점수):** 고객의 신용 점수를 나타내는 수치값
- **Geography(지역):** 고객이 거주하는 국가
- **Gender(성별):** 고객의 성별
- **Age(나이):** 고객의 나이
- **Tenure(이용기간):** 고객이 은행에 머무른 연수(은행을 이용한 햇수)
- **Balance(예금 잔액):** 고객의 계좌 잔액
- **NumOfProducts(상품 개수):** 고객이 사용하는 은행 상품의 수 (예: 적금, 신용 카드 등)
- **HasCrCard(신용카드 보유 여부):** 고객이 신용카드를 소지하고 있는지 여부
- **IsActiveMember(활동 회원 여부):** 고객이 활동 회원인지 여부
- **EstimatedSalary(추정 급여):** 고객의 추정 급여
- **Exited(이탈 여부):** 고객의 이탈 여부

---

# 분석 목표

- **예금 잔액**과 **상품 개수**, **나이**, **거주지역의 관계**에 대한 유의미한 분석 결과 도출

---

# 분석 과정(개요)

## 종속변수

- Balance(예금 잔액)

## 독립변수

- NumOfProducts(상품 개수)
    - 가입한 상품의 개수와 예금 잔액에 대한 관계성이 있는지에 대한 궁금증
    - **COMMENT ;** 본 데이터셋에서 한 사람이 보유한 최대의 상품 개수는 4개였습니다.
- Age(나이)
    - 연령과 예금 잔액에 대한 관계성이 있는지에 대한 궁금증
- Geography(지역)
    - 거주 지역과 예금잔액에 대한 관계성이 있는지에 대한 궁금증
    - **COMMENT ;** 본 데이터셋에는 총 3개의 나라만 포함되어있었습니다. (독일, 스페인, 프랑스)

## 중간 목표

- 종속변수와 각 독립변수들간의 관계를 분석합니다.
    1. ‘Balance’와 ‘NumOfProducts’
    2. ‘Balance’와 'Age’
    3. ‘Balance’와 ‘Geography’

## 가설설정

**각 중간 목표에 관한 가설 설정은 하위에서 다룹니다.**

- 귀무가설 : 독립변수가 종속변수에 영향을 주지 않는다.
- 대립가설 : 독립변수가 종속변수에 영향을 준다.

---

# 분산분석 수행

## 분산분석

![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled.jpeg)

- 우리는 예금 잔액과 상품 개수, 나이, 거주지역의 관계에 대한 유의미한 분석 결과 도출하기 위해 분산분석을 진행하기로 했습니다.
    - **위 자료는 분산분석에 대한 기본적인 분석방향에 대한 도식입니다.**
    
    - 분산분석(ANOVA, Analysis of Variance)은 통계적인 방법 중 하나로, 여러 그룹 간의 평균 차이를 검정하는 데 사용됩니다.
    - 주로 세 개 이상의 그룹 간의 평균 차이를 비교하고자 할 때 효과적입니다.
    - 분산분석은 그룹 간의 변동과 그룹 내의 변동을 비교하여 특정 요인이 변동에 미치는 영향을 확인합니다.

## 라이브러리 사용

- pandas
- seaborn
- scipy
- pingouin
    - 분산분석을 효율적으로 수행하기 위해 [pingouin](https://pingouin-stats.org/build/html/index.html) 라이브러리를 활용하여 분산분석을 수행합니다.
    - 참고자료 : [pingouin.org](https://pingouin-stats.org/build/html/guidelines.html)

## 분산분석 개요

![2.jpg](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/2.jpg)

- 앞으로의 분석과정에 대한 간단한 개요는 다음과 같습니다.
    - 기본적으로 샘플의 수가 많으므로 정규성을 띈다고 가정
    - 각 중간 목표의 등분산성을 만족하는지 확인
        - 만족하는 경우 : 일반 분산분석을 진행
            - 사후검정 : Turkey-HSD 검정을 진행
        - 만족하지 못하는 경우 : Welch 분산 분석을 진행
            - 사후검정 : Games-Howell 검정을 진행

---

# 데이터 가공(샘플 데이터 추출)

**범주가 너무 넓어 분석의 효율성을 높이기 위해 샘플 데이터를 추출하기로 결정하였습니다.**

- **정규분포를 따르기 위해 데이터 개수는 30개 이상인 20,000개로 랜덤 추출하였습니다.**
- 포함된 데이터 중 ‘Age’ 컬럼의 데이터는 경제활동을 할 수 있는 나이의 데이터로 샘플 데이터를 추출하였습니다.
    - 경제 활동이 가능한 나이에 대한 근거 : 정년퇴임 ( 20세~65세 )

- 최초 1회에 한해 20000개의 데이터를 랜덤 추출 하였습니다.
    
    
    ```python
    sample_train = train_data.sample(n=20000, replace =False)
    ```
    

---

# 등분산성 만족여부 분석

## **가설 설정**

- H0 : 표본 집단간의 분산의 차이가 없다.
- H1 : 표본 집단간의 분산의 차이가 있다.

## 등분산성 만족여부 분석

### 등분산성 검정 - **‘Balance’와 ‘NumOfProducts’**

- // **TOGGLE ME //**
    
    ## **데이터 프레임화**
    
    **NumOfProduct 컬럼에는 1부터 4까지의 값으로 4가지 그룹으로 나눌 수 있었습니다.**
    
    - 따라서 아래와 같이 데이터 샘플 추출을 진행하였습니다.
        - 상품을 1개 가진 사람의 데이터 : df1
        - 상품을 2개 가진 사람의 데이터 : df2
        - 상품을 3개 가진 사람의 데이터 : df3
        - 상품을 4개 가진 사람의 데이터 : df4
    
    ```python
    df1 = sample_train.loc[train_data['NumOfProducts'] == 1, 'Balance']
    df2 = sample_train.loc[train_data['NumOfProducts'] == 2, 'Balance']
    df3 = sample_train.loc[train_data['NumOfProducts'] == 3, 'Balance']
    df4 = sample_train.loc[train_data['NumOfProducts'] == 4, 'Balance']
    ```
    
    ## **등분산성 검증**
    
    ### 코드
    
    ```python
    from scipy.stats import bartlett
    
    print(stats.bartlett(df1, df2, df3, df4))
    ```
    
    ### 실행**결과**
    
    ![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled.png)
    
    ### 결과 해석
    
    **P-value**의 값이 **0.05 이하**로 나타났으므로 **귀무가설을 기각(H1 채택), 등분산성을 만족하지 못합니다.**
    
    - 데이터가 정규성을 띄고 있으나, 등분산성을 만족하지 못하는 결과가 도출되었습니다.
    - 그러므로 다음 단계에서 Welchs-ANOVA 검정을 진행하도록 하겠습니다.
    

### 등분산성 검정 -  **‘Balance’와 'Age’**

- // **TOGGLE ME //**
    
    ## **데이터 프레임화 + 데이터 가공**
    
    ```python
    dataset_filter = sample_train.copy()
    bins = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
    labels = ['10-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']
    dataset_filter['Agedata'] = pd.cut(dataset_filter['Age'], bins=bins, labels=labels, right=False)
    age_data_filter= dataset_filter.loc[(dataset_filter['Agedata'] == '21-30')|(dataset_filter['Agedata'] == '31-40')|(dataset_filter['Agedata'] == '41-50')|(dataset_filter['Agedata'] == '51-60'),:]
    
    df20 = age_data_filter.loc[age_data_filter['Agedata'] == '21-30', 'Balance']
    df30 = age_data_filter.loc[age_data_filter['Agedata'] == '31-40', 'Balance']
    df40 = age_data_filter.loc[age_data_filter['Agedata'] == '41-50', 'Balance']
    df50 = age_data_filter.loc[age_data_filter['Agedata'] == '51-60', 'Balance']
    
    ```
    
    ## /gree**등분산성 검증**
    
    ### 코드
    
    ```python
    from scipy.stats import bartlett
    
    print(stats.bartlett(df20, df30, df40, df50))
    ```
    
    ### 실행**결과**
    
    ![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled%201.png)
    
    ### 결과 해석
    
    **P-value**의 값이 **0.05 이하**로 나타났으므로 **귀무가설을 기각(H1 채택), 등분산성을 만족하지 못합니다.**
    
    - 데이터가 정규성을 띄고 있으나, 등분산성을 만족하지 못하는 결과가 도출되었습니다.
    - 그러므로 다음 단계에서 Welchs-ANOVA 검정을 진행하도록 하겠습니다.
    

### 등분산성 검정 -  **‘Balance’와 ‘Geography’**

- // **TOGGLE ME //**
    
    ## **데이터 프레임화**
    
    - Geography 컬럼에는 Spain, Germany, France 값 3가지가 전제되어있었습니다.
        - 따라서 아래와 같이 데이터 샘플 추출을 진행하였습니다.
            - Spain 데이터 : df_spain
            - Germany 데이터 : df_germany
            - France 데이터 : df_spain
        
    
    ```python
    df_spain = sample_train.loc[train_data['Geography'] == 'Spain', 'Balance']
    df_germany = sample_train.loc[train_data['Geography'] == 'Germany', 'Balance']
    df_france = sample_train.loc[train_data['Geography'] == 'France', 'Balance']
    ```
    
    ## **등분산성 검증**
    
    ### 코드
    
    ```python
    from scipy.stats import bartlett
    
    print(stats.bartlett(df_spain, df_germany, df_france))
    ```
    
    ### 실행**결과**
    
    ![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled%202.png)
    
    ### 결과 해석
    
    **P-value**의 값이 **0.05 이하**로 나타났으므로 **귀무가설을 기각(H1 채택), 등분산성을 만족하지 못합니다.**
    
    - 데이터가 정규성을 띄고 있으나, 등분산성을 만족하지 못하는 결과가 도출되었습니다.
    - 그러므로 다음 단계에서 Welchs-ANOVA 검정을 진행하도록 하겠습니다.
    

---

# ANOVA 검정 수행

## 개요

- 공교롭게도 3가지 중간목표 모두 등분산성을 만족하지 않는 것으로 나타났습니다.
    - 이전 단계에서의 결론 : 정규성을 띄나 등분산성을 띄지 않음
    - 따라서 이번 단계에서는 Welchs ANOVA 검정을 수행하도록 하겠습니다.

### ANOVA 검정- **‘Balance’와 ‘NumOfProducts’**

- **// TOGGLE ME //**
    
    ### 가설설정
    
    - H0 :  4개의 집단간 유의미한 잔고의 평균의 차이가 존재하지 않음
    - H1 : 4개의 집단간 하나라도 잔고의 유의미한 평균의 차이 존재함.
    
    ## Welchs-ANOVA 검정
    
    ### 코드
    
    ```python
    import pingouin as pg
    pg.welch_anova(dv='Balance', between='NumOfProducts', data=sample_train)
    ```
    
    ### 실행결과
    
    ![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled%203.png)
    
    ### 결과해석
    
    **P-value**의 값이 **0.05 이하**로 나타났으므로 **귀무가설을 기각(H1 채택), 4개 집단간 하나라도 유의미한 평균의 차이가 존재한다고 볼 수 있습니다.**
    

### ANOVA 검정 - **‘Balance’와 ‘Age’**

- **// TOGGLE ME //**
    
    ### 가설설정
    
    - H0 :  각 연령대별 간 잔고의 유의미한 평균의 차이가 존재하지 않음
    - H1 : 각 연령대별 간 하나라도 잔고의 유의미한 평균의 차이가 존재함
    
    ## Welchs-ANOVA 검정
    
    ### 코드
    
    ```python
    import pingouin as pg
    pg.welch_anova(dv='Balance', between='Agedata',data=age_data_filter)
    ```
    
    ### 실행결과
    
    ![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled%204.png)
    
    ### 결과해석
    
    **P-value**의 값이 **0.05 이하**로 나타났으므로 **귀무가설을 기각(H1 채택), 각 연령대별 간 유의미한 평균의 차이가 존재한다고 볼 수 있습니다.**
    

### ANOVA 검정 - **‘Balance’와 ‘Geography’**

- **// TOGGLE ME //**
    
    ### 가설설정
    
    - H0 :  3개의 집단간 잔고의 유의미한 평균의 차이가 존재하지 않음
    - H1 : 3개의 집단간 하나라도 잔고의 유의미한 평균의 차이 존재함.
    
    ## Welchs-ANOVA 검정
    
    ### 코드
    
    ```python
    import pingouin as pg
    pg.welch_anova(dv='Balance', between='Geography',data=sample_train)
    ```
    
    ### 실행결과
    
    ![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled%205.png)
    
    ### 결과해석
    
    **P-value**의 값이 **0.05 이하**로 나타났으므로 **귀무가설을 기각(H1 채택), 4개 집단간 유의미한 평균의 차이가 존재한다고 볼 수 있습니다.**
    

---

# 사후검정 수행(Games-Howell 검정)

## 서론

- 사후검정은 분산분석에서 귀무가설이 기각이 되었을 때 즉 **표본집단들의 표본평균값의 평균과 각 표본집단의 표본평균과의 차이(표본집단간의 표본평균 분산)**가 발생했을 때 분산분석만으로는 어떤 요인에 의해 표본집단들의 표본평균값의 평균과 표본집단의 표본평균과의 차이**(표본집단간의 평균의 차이)**가 유의미하게 발생하는지 알 수가 없다. 그렇기에 사후검정을 통해 각각의 요인을 t-test를 통해 확인을 하게 된다.
- 따라서 사후검정을 통해 각 요인에 대한 t-test를 진행하여 검정을 진행하게 됩니다.
- 우리가 사후검정에서 중점적으로 봐야하는 값은 p-Value 값도 있으나 t-Value, 즉 T통계량으로 이것을 확인하게 됩니다.
    - t-Value 값이 크다는 것은 우리가 선택한 요인들, 즉 표본집단의 평균의 차이가 크게 난다는 것을 의미합니다.
    - 시각화 자료(그래프)에서는 서로 멀리 떨어져있다는 것을 의미합니다.
    - 여러 표본집단에 의한 분산분석을 진행할 때 p-Value에 의해 표본평균들의 차이가 유의미하게 나타난다고 해석할 수 있습니다.
    

## 개요

- 공교롭게도 3가지 중간목표 모두 각 컬럼의 집단들 간의 평균의 차이가 존재하는 결론이 도출되었습니다.
    - 단, 분산분석은 표본집단간 평균의 평균차가 존재할 수 있으므로 사후검정을 진행해야합니다.
    - 따라서 이번 단계에서는 Games-Howell 검정을 수행하도록 하겠습니다.

<aside>
💡 **이전 단계에서 pingouin 라이브러리를 임포트하였으므로, 이 단계에서는 생략합니다.**

</aside>

### 사후검정 - **‘Balance’와 ‘NumOfProducts’**

- **// TOGGLE ME //**
    
    ### 코드
    
    ```python
    Num_games_howell = pg.pairwise_gameshowell(data=sample_train, dv='Balance', between='NumOfProducts')
    print(num_games_howell)
    ```
    
    ### 실행결과
    
    ![스크린샷 2024-01-16 오후 4.29.58.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.29.58.png)
    
    ### 시각화
    
    ![스크린샷 2024-01-16 오후 5.01.27.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.01.27.png)
    
    ![스크린샷 2024-01-16 오후 5.21.55.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.21.55.png)
    

### 사후검정 - **‘Balance’와 ‘Age’**

- **// TOGGLE ME //**
    
    ### 코드
    
    ```python
    Age_games_howell = pg.pairwise_gameshowell(data=age_data_filter, dv='Balance', between='Agedata')
    print(Age_games_howell)
    ```
    
    ### 실행결과
    
    ![스크린샷 2024-01-16 오후 3.23.48.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.23.48.png)
    
    ### 시각화
    
    ![스크린샷 2024-01-16 오후 5.44.13.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.44.13.png)
    
    ![스크린샷 2024-01-16 오후 5.42.39.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.42.39.png)
    

### 사후검정 - **‘Balance’와 ‘Geography’**

- **// TOGGLE ME //**
    
    ### 코드
    
    ```python
    Geo_games_howell = pg.pairwise_gameshowell(data=sample_train, dv='Balance', between='Geography')
    print(Geo_games_howell)
    ```
    
    ### 실행결과
    
    ![스크린샷 2024-01-16 오후 3.23.08.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.23.08.png)
    
    ### 시각화
    
    ![스크린샷 2024-01-16 오후 6.11.55.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_6.11.55.png)
    
    ![스크린샷 2024-01-16 오후 5.39.27.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.39.27.png)
    

---

# 시각화 수행 및 중간목표 해석

## ‘Balance’와 ‘Age’의 관계 시각화

<aside>
💡 ‘Age’가 **`연속형 변수`**이므로 범위를 세분화 할 필요가 있음.
Ex)
10 - 20, 21 - 30, 31 - 40, etc …

</aside>

![스크린샷 2024-01-16 오후 6.04.52.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_6.04.52.png)

위 그래프의 결과를 통해 **NumberOfProducts**가 가장 많은 **4개의 그룹**을 선택하였다.

- Selected group
    - 21-30, 31-40, 41-50, 51-60

```python
# 1. 깊은 복사를 통해 원본 데이터에 영향을 주지 않고 'Age' 열에 해당하는 데이터만 추출
df_age = train_data[['Age']].copy()
df_age
```

```python
# 2. 연령대를 나누기 위한 구간 설정
bins = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
labels = ['10-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']

# 3. 'Age' 열을 이용하여 연령대 구분을 수행하고 바로 그룹별 평균 계산에 사용
age_group_balance = train_data.groupby(pd.cut(train_data['Age'], bins=bins, labels=labels, right=False))['Balance'].mean().reset_index(name='AverageBalance')

# 4. 결과 확인
age_group_balance
```

![스크린샷 2024-01-16 오후 1.25.20.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.25.20.png)

```python
# 연령대 그룹별 평균 'Balance'를 시각화하는 코드 수정
# 21-30, 31-40, 41-50, 51-60 연령대 그룹만 시각화

# 지정된 연령대 그룹만 필터링
filtered_age_group_balance = age_group_balance[age_group_balance['Age'].isin(['21-30', '31-40', '41-50', '51-60'])]

# 인덱스 초기화하기 : 그래프 그리기 유용하게 하기 위해
filtered_age_group_balance = filtered_age_group_balance.reset_index(drop=True)

# 시각화
plt.figure(figsize=(12, 6))
ax = sns.barplot(
    x='Age', 
    y='AverageBalance', 
    data=filtered_age_group_balance, 
    palette='viridis',
    order=['21-30', '31-40', '41-50', '51-60']  # 이 순서대로 막대그래프 표시
)

# 상단 제목 설정
plt.title('Average Balance per Age Group (21-60)')

# x축 레이블 설정
plt.xlabel('Age Group')

# y축 레이블 설정
plt.ylabel('Average Balance')
plt.xticks(rotation=45)

# 지정한 범위로 x축 지정하기
ax.set_xticks(range(len(filtered_age_group_balance['Age'])))
ax.set_xticklabels(filtered_age_group_balance['Age'])

# 각 막대 위에 정확한 값을 표시 (소수점 없이 반올림)
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.0f'), 
                (p.get_x() + p.get_width() / 2., p.get_height()), 
                ha='center', va='center', 
                xytext=(0, 10), 
                textcoords='offset points')

# 그래프 간격 수정
plt.tight_layout()

# 그래프 그리기
plt.show()
```

![스크린샷 2024-01-16 오후 5.44.13.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.44.13.png)

![스크린샷 2024-01-16 오후 5.42.39.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.42.39.png)

<aside>
💡 **`그래프 분석`
데이터 셋이 몇년도를 기준으로 한 것인지 알 수 없어 그래프를 통해 분석을 진행하였다.
연령층이 증가할 수록 평균 통장 잔고가 증가하는 것을 알 수 있었으며 Balance와 Age의 관계성을 선형 회귀식을 통해 한번 더 알아보고자 한다.**

</aside>

<aside>
💡 **[요인들에 대한 t-test 결과 해석]**

4개의 그룹에서 2개를 비교하는 경우의 수는 4C2 = 6가지가 나오게 된다.

표는 'A', 'B', 'T' 세 개의 열을 가지고 있으며
'A'와 'B'는 연령대를 나타내며, 'T'는 연령대 간의 평균 잔액 차이를 나타내며

연령대가 높아질수록 평균 잔액이 증가하는 경향이 있다는 것을 알 수 있습니다.

</aside>

![스크린샷 2024-01-16 오후 7.06.33.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_7.06.33.png)

위 그래프를 봤을 때, 연령(Age)과 은행 잔고(Balance) 사이에는 어느 정도 관계성이 있다는 것을 알 수 있다. 

빨간색 선형 회귀선은 나이가 많을수록 은행 잔고가 증가하는 경향을 나타낸다. 

그러나 데이터 포인트들이 넓게 퍼져 있고, 많은 데이터 포인트들이 회귀선에서 멀리 떨어져 있기 때문에, 개별적인 변동성이 매우 크다는 것을 알 수 있으며 이는 나이가 많다고 해서 반드시 통장 잔고가 높은 것은 아니라는 것을 의미한다.

데이터 포인트들의 이러한 넓은 분포는 다른 요인들이 잔고에 영향을 미칠 수 있음을 시사한다. 예를 들어, 개인의 소득, 저축 습관, 지출 패턴, 투자 결정 등이 잔고에 영향을 줄 수 있다. 

이러한 요인들은 연령과 함께 변할 수 있으며, 개인에 따라 다르게 나타날 수 있다.

회귀선은 이러한 모든 변동성을 하나의 선형 패턴으로 단순화하여 표현하는데, 실제 개별 데이터 포인트들은 이 선에서 상당히 벗어날 수 있다. 

그러므로, 연령과 잔고 사이에는 통계적으로 유의미한 상관관계가 있을 수 있지만, 이 관계는 약하고 다른 많은 요인들에 의해 영향을 받을 수 있으며 완전한 분석을 위해서는 추가적인 통계적 검정과 다변량 분석이 필요하다.

## ‘Balance’와 ‘Geography’의 관계 시각화

```python
# Geography
df_Geography = train_data[['Geography']].copy()
df_Geography
```

```python
# 각 나라별로 평균 통장 잔고 계산
geography_balacne = train_data.groupby('Geography')['Balance'].mean().reset_index(name='AverageBalacne')

# 시각화
plt.figure(figsize=(12, 6))
ax = sns.barplot(data=geography_balacne, x='Geography', y='AverageBalacne', palette='viridis')
plt.title('Average Balance per Geography')
plt.xlabel('Geography')
plt.ylabel('Average Balance')

# 각 막대 위에 평균 통장 잔고의 정확한 값을 표시 (소수점 없이 반올림)
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.0f'), 
                (p.get_x() + p.get_width() / 2., p.get_height()), 
                ha='center', va='center', 
                xytext=(0, 10), 
                textcoords='offset points')

plt.tight_layout()
plt.show()
```

![스크린샷 2024-01-16 오후 6.11.55.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_6.11.55.png)

![스크린샷 2024-01-16 오후 5.39.27.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.39.27.png)

분석 결과 Geography와 Balance의 관계가 뚜렷하게 나타나 실제 자료를 조사해보고 비교해보았다.

**시각화와 통계 분석** : t-value값이 크다는 것은 두 그래프간의 평균의 차이가 크다는 것을 의미하며 불확실성(표본집단의 분산)이 작다는 것을 의미 여기서 우리는 평균의 차이가 t-value값의 큰 영향을 준다. 그렇기에 사후검정을 한 결과값을 보면 스페인과 프랑스는 나라별 잔고의 차이가 상대적으로 크지 않지만 독일과는 큰 차이가 난다는 것을 시각화 자료와 통계적 자료로 볼 수 있다.우리가 참고했던 자료를 보면 국내 총 생산량과 1인 GDP를 보았을 때도 독일과 두나라는 큰 차이가 났었으나 스페인과 프랑스는 큰 차이가 나지 않는다는 것을 보았는데 실제 데이터로 결과를 냈었을 때도 이와 비슷한 양상을 따르는 것을 볼 수 있었다.

참고자료 찾기

[https://namu.wiki/w/국가별 1인당 GNI 순위(구매력 기준)](https://namu.wiki/w/%EA%B5%AD%EA%B0%80%EB%B3%84%201%EC%9D%B8%EB%8B%B9%20GNI%20%EC%88%9C%EC%9C%84(%EA%B5%AC%EB%A7%A4%EB%A0%A5%20%EA%B8%B0%EC%A4%80))

[국내 총생산 - 국가 목록 - 유럽](https://ko.tradingeconomics.com/country-list/gdp?continent=europe)

## ‘Balance’와 ‘NumOfProducts’의 관계 시각화

### 1-1.  전체 데이터를 기준으로 막대 그래프 그리기

```python
# 'NumOfProducts' 열을 기준으로 값의 개수를 계산
product_counts = train_data['NumOfProducts'].value_counts()

# 시각화 설정
plt.figure(figsize=(12, 6))
ax = sns.barplot(x=product_counts.index, y=product_counts.values)
colors = sns.color_palette("muted")

# 각 막대 위에 정확한 개수 표시
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.0f'),  # 높이를 정수 형식으로 표현
                (p.get_x() + p.get_width() / 2., p.get_height()), 
                ha='center', va='center', 
                xytext=(0, 10), 
                textcoords='offset points')

plt.title('Number of Products Distribution')
plt.xlabel('Number of Products')
plt.ylabel('Count')
plt.show()

```

![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/Untitled.png)

<aside>
💡 **상품의 개수가 1개, 2개인 경우가 다반수**

</aside>

---

### 1-2.  샘플 데이터를 기준으로 막대 그래프 그리기

```python
samaple_train = train_data.sample(n=20000, replace=False)

# 'NumOfProducts' 열을 기준으로 값의 개수를 계산
sample_product_counts = samaple_train['NumOfProducts'].value_counts()

# 시각화 설정
plt.figure(figsize=(12, 6))
ax = sns.barplot(x=sample_product_counts.index, y=sample_product_counts.values)
colors = sns.color_palette("muted")

# 각 막대 위에 정확한 개수 표시
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.0f'),  # 높이를 정수 형식으로 표현
                (p.get_x() + p.get_width() / 2., p.get_height()), 
                ha='center', va='center', 
                xytext=(0, 10), 
                textcoords='offset points')

plt.title('Number of Products Distribution')
plt.xlabel('Number of Products')
plt.ylabel('Count')
plt.show()
```

![스크린샷 2024-01-16 오후 3.38.55.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.38.55.png)

<aside>
💡 **전체데이터와 마찬가지로 상품의 개수가 1개, 2개인 경우가 다반수**

</aside>

### 1-3.

```python
# 'NumOfProducts'로 그룹화하고 'Balance'의 평균 계산
df6 = train_data.copy()
grouped_data = df6.groupby('NumOfProducts')['Balance'].mean()

# x와 y 데이터 준비
x = grouped_data.index.astype(str)
y = grouped_data.values

# 시각화
plt.figure(figsize=(12, 8))
colors = sns.color_palette("muted")
ax = sns.barplot(x=x, y=y, palette=colors) # orient='v'는 기본값이므로 생략 가능
ax.set_xlabel('Number of Products', fontsize=16)
ax.set_ylabel('Average Balance', fontsize=16)
ax.set_title('Average Balance per Number of Products', fontsize=20)

# 각 막대 위에 정확한 수치 표시 (소수점 없이 반올림)
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.0f'),(p.get_x() + p.get_width() / 2, p.get_height()),
            ha='center', va='bottom', fontsize=12)
```

![스크린샷 2024-01-16 오후 5.01.27.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.01.27.png)

![스크린샷 2024-01-16 오후 5.21.55.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.21.55.png)

---

### 1-4. ‘Balance’와 ‘NumOfProducts’의 관계 파이 차트

```python
# 'NumOfProducts'로 그룹화하고 'Balance'의 평균 계산
df6 = train_data.copy()
grouped_data = df6.groupby('NumOfProducts')['Balance'].mean()

# 파이 차트 그리기
plt.figure(figsize=(8, 8))
plt.pie(grouped_data, labels=grouped_data.index, autopct='%1.1f%%', startangle=140)
plt.title('Pie Chart of Average Balance per Number of Products')
plt.show()
```

![스크린샷 2024-01-16 오후 3.57.11.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.57.11.png)

---

### 1-5. ‘Balance’와 ‘NumOfProducts’의 관계 바이올린 플롯

```python
# 'NumOfProducts'로 그룹화하고 'Balance'의 평균 계산
df6 = train_data.copy()
grouped_data = df6.groupby('NumOfProducts')['Balance'].mean()

# x와 y 데이터 준비
x = grouped_data.values
y = grouped_data.index.astype(int) # 정수형으로 그리기

# 바이올린 플롯 그리기
plt.figure(figsize=(6, 6))
ax = sns.violinplot(x='NumOfProducts', y='Balance', data=df6, palette="muted")
ax.set_xlabel('Number of Products', fontsize=16)
ax.set_ylabel('Balance', fontsize=16)
ax.set_title('Distribution of Balance per Number of Products', fontsize=20)

# 각 바이올린 위에 평균값 표시
for i in range(len(grouped_data)):
    ax.text(i, grouped_data.iloc[i], f'{grouped_data.iloc[i]:.0f}', 
            ha='center', va='bottom', fontsize=12, color='black')

plt.show()
```

![스크린샷 2024-01-16 오후 3.57.58.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.57.58.png)

<aside>
💡 1, 2, 3, 4개의 상품을 가진 고객들의 ‘Balance’ 평균 비율을 비교
1개와 4개의 상품을 가진 고객들이 가장 큰 비율을 차지하며, 상대적으로 높은 ‘Balance’를 가지고 있는 것으로 보임.
2개의 상품을 가진 고객들은 비교적 작은 비율을 차지하며, ‘Balance’가 낮음.

</aside>

---

# 의문점

## ‘Balance’와 ‘NumOfProducts’의 관계

![스크린샷 2024-01-16 오후 5.01.27.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-16_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.01.27.png)

- 상품을 1개 보유한 고객보다, 2개를 보유한 고객이 예금한 잔액이 더 줄어든다는 결론

![Untitled](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%204%E1%84%8C%E1%85%A9%20e57d272319f64ed4ba3faadd3c989c50/%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%20add909d41a6844fd9ecae2adac0d7b63/Untitled.png)

- 상품 보유 수가 2개인 데이터가 많은 이유는, 통상적으로 예금통장을 개설하면서 신용카드를 발급받기 때문일 것 같다는 추측을 하게 되었습니다.
    - 적금, 대출 등의 다른 상품에 대한 데이터가 없어 신용카드 보유 여부에 대한 분석만 가능
- 이 추측이 사실인지 확인 추가적인 분석을 진행하기로 했습니다.

---

# 추가 분석 진행

- 데이터를 살펴보다 보니, ‘HasCrCard’ 컬럼이 신용카드 보유 여부에 대한 데이터라는 것을 발견하게 되었습니다.

![스크린샷 2024-01-17 오전 10.15.13.png](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-17_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.15.13.png)

2개의 상품을 보유한 그룹을 대상으로 신용카드 보유여부에 대한 분석을 진행했는데, 신용카드를 보유한 비율이 훨씬 높았습니다.

# 결론 정리 및 분석 제시

### 결론 제시

따라서 중간 목표의 결론과, 이후의 의문점을 종합적으로 고려했을 때 도출된 결론을 정리하자면 아래와 같습니다.

- **중간 목표의 결론 :** 상품 개수가 2개인 경우 예금 보유 잔액이 줄어든다.
- **의문점의 결론 :** 상품을 2개 보유한 고객은 신용카드를 보유한 사람이 훨씬 많다.

### 분석 제시

은행이 신규 고객을 모집할 때, 예금통장을 개설하면서 신용카드 발급을 하지 않도록 하면 은행이 보유하게 될 예금이 증가한다는 결론이 도출되었습니다.

# 의의와 한계

- 상품을 3개 이상 보유한 고객부터는 다시 예금 잔액이 증가하는 것으로 보았을 때,
예금 잔액이 많아질 때 상품의 가입 수가 많아진다는 분석도 가능
    - 사람마다 소득에 따른 차이가 있으므로 표본이 적은 것도 설명이 가능
        
        ![SOURCE : [통계청](https://kostat.go.kr/menu.es?mid=b80202000000)](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-01-17_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.48.04.png)
        
        SOURCE : [통계청](https://kostat.go.kr/menu.es?mid=b80202000000)
        
- 그러나 신용카드 보유 여부에 대한 데이터만 존재하고, 적금, 대출, 투자 상품 등 다른 상품에 대한 데이터가 존재하지 않아 추가적인 분석이 어려웠음

---

## **멀티캠퍼스 멀티잇 데이터 분석 & 엔지니어 34회차 4조 (1/4 ~ 1/17)**

### 코드

```python
import platform

def is_mac():
	if platform.system() == 'Darwin':
	    return "맥 사용자 입니다."
	else:
	    return "맥 사용자가 아닙니다."

# 우리 조의 구성원
group4 = ['송민', '양인선', '윤지훈', '박지건', '김태기', '김영기']

for i in group4:
	print(f'{i}님은 {is_mac()}')
```

### 실행결과

![저희 조는 Mac 사용을 하는 사람들끼리 모이게 되었습니다!](%5B%E1%84%86%E1%85%A5%E1%86%AF%E1%84%8F%E1%85%A2%E1%86%B7%5D%204%E1%84%8C%E1%85%A9%20%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A9%E1%84%80%E1%85%B5%E1%86%BC%2073092ce5898247328650cb17e5cea40e/Untitled%206.png)

저희 조는 Mac 사용을 하는 사람들끼리 모이게 되었습니다!